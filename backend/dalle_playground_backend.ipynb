{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "118UKH5bWCGa"
      },
      "source": [
        "<center><img src=\"https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/240/apple/285/woman-artist_1f469-200d-1f3a8.png\" width=\"120\">\n",
        "</center>\n",
        "\n",
        "### <center>Use this notebook to run your DALL-E server</center>\n",
        "### <center> [DALL-E Playground Repository](https://github.com/saharmor/dalle-playground) </center>\n",
        "\n",
        "[DC fork](https://github.com/dcsan/dalle-playground)\n",
        "\n",
        "#####<center>This notebook is based on the amazing [DALL·E Mini](https://github.com/borisdayma/dalle-mini) by [Boris Dayma](https://github.com/borisdayma) et al.</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS8LbaonYm3a"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyO_o-lTQn2A"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/saharmor/dalle-playground.git\n",
        "!pip install -r dalle-playground/backend/requirements.txt\n",
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itw9hJxfl1bJ"
      },
      "source": [
        "## Choose a model\n",
        "\n",
        "* **DALL-E Mini**\n",
        "  * The original DALL-E Mini. Fastest yet suboptimal results\n",
        "  * Runs well on a 4GB GPU and the Google Colab free tier\n",
        "* **DALL-E Mega**\n",
        "  * The advanced version of DALL-E Mini. Requires more compute and VRAM\n",
        "  * Runs well on a 8GB GPU and recommended on the Google Colab Pro tier\n",
        "* **DALL-E Mega Full**\n",
        "  * The most performant DALL-E version. Requires significantly more computre and VRAM\n",
        "  * Runs well on a 12GB GPU and recommended on the Google Colab Pro+ tier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXjTocicwQmD"
      },
      "outputs": [],
      "source": [
        "# check run time type to see if we have a GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BKmwZUHcl1bK"
      },
      "outputs": [],
      "source": [
        "#@title Select a model - remember to execute cell after selecting!\n",
        "\n",
        "dalle_model = 'Mega_full' #@param [\"Mini\", \"Mega\", \"Mega_full\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rb_IBiwwQmD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqF_iNGmmVIC"
      },
      "source": [
        "# Run the backend web server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrRYWN7qTioY",
        "outputId": "88864206-6919-4a54-c0ec-78ab8bbc2ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected DALL-E Model - [Mega]\n",
            "--> Starting DALL-E Server. This might take up to two minutes.\n",
            "your url is: https://metal-points-itch-35-231-76-21.loca.lt\n",
            "tcmalloc: large alloc 5175050240 bytes == 0xbcc6000 @  0x7f61f57841e7 0x4a3940 0x5b438c 0x5ea94f 0x5939cb 0x594cd3 0x5d0ecb 0x59aeca 0x515655 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549e0e 0x593fce 0x548ae9 0x5127f1 0x4bc98a 0x532b86 0x594a96 0x515600 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f61f5381c87 0x5b621a\n",
            "Some of the weights of DalleBart were initialized in float16 precision from the model checkpoint at /tmp/tmpszd3x2ts:\n",
            "[('lm_head', 'kernel'), ('model', 'decoder', 'embed_positions', 'embedding'), ('model', 'decoder', 'embed_tokens', 'embedding'), ('model', 'decoder', 'final_ln', 'bias'), ('model', 'decoder', 'layernorm_embedding', 'bias'), ('model', 'decoder', 'layernorm_embedding', 'scale'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_1', 'k_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_1', 'out_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_1', 'q_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'FlaxBartAttention_1', 'v_proj', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'GLU_0', 'LayerNorm_0', 'bias'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'GLU_0', 'LayerNorm_1', 'bias'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'LayerNorm_0', 'bias'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'LayerNorm_1', 'bias'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'LayerNorm_1', 'scale'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'LayerNorm_2', 'bias'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'LayerNorm_3', 'bias'), ('model', 'decoder', 'layers', 'FlaxBartDecoderLayers', 'LayerNorm_3', 'scale'), ('model', 'encoder', 'embed_positions', 'embedding'), ('model', 'encoder', 'embed_tokens', 'embedding'), ('model', 'encoder', 'final_ln', 'bias'), ('model', 'encoder', 'layernorm_embedding', 'bias'), ('model', 'encoder', 'layernorm_embedding', 'scale'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'FlaxBartAttention_0', 'k_proj', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'FlaxBartAttention_0', 'out_proj', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'FlaxBartAttention_0', 'q_proj', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'FlaxBartAttention_0', 'v_proj', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'GLU_0', 'Dense_0', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'GLU_0', 'Dense_1', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'GLU_0', 'Dense_2', 'kernel'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'GLU_0', 'LayerNorm_0', 'bias'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'GLU_0', 'LayerNorm_1', 'bias'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'LayerNorm_0', 'bias'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'LayerNorm_1', 'bias'), ('model', 'encoder', 'layers', 'FlaxBartEncoderLayers', 'LayerNorm_1', 'scale')]\n",
            "You should probably UPCAST the model weights to float32 if this was not intended. See [`~FlaxPreTrainedModel.to_fp32`] for further information on how to do this.\n",
            "Downloading: 100% 434/434 [00:00<00:00, 478kB/s]\n",
            "Downloading: 100% 290M/290M [00:06<00:00, 47.1MB/s]\n",
            "Downloading: 100% 34.2M/34.2M [00:01<00:00, 24.2MB/s]\n",
            "--> DALL-E Server is up and running!\n",
            "--> Model selected - DALL-E ModelSize.MEGA\n",
            " * Serving Flask app 'app' (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n",
            "INFO:werkzeug: * Running on all addresses (0.0.0.0)\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            " * Running on http://127.0.0.1:8000\n",
            " * Running on http://172.28.0.2:8000 (Press CTRL+C to quit)\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 06:55:19] \"OPTIONS / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 06:55:19] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 06:55:24] \"OPTIONS /dalle HTTP/1.1\" 200 -\n",
            "Created 2 images from text prompt [a fish jumping out of the bowl]\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 06:55:48] \"POST /dalle HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 06:56:09] \"OPTIONS /dalle HTTP/1.1\" 200 -\n",
            "Created 2 images from text prompt [a beautiful girl putting on make up]\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 06:56:33] \"POST /dalle HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 06:56:56] \"OPTIONS /dalle HTTP/1.1\" 200 -\n",
            "Created 2 images from text prompt [a beautiful girl putting on make up photo by Richard Avedon for Vogue ]\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 06:57:20] \"POST /dalle HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 06:57:39] \"OPTIONS /dalle HTTP/1.1\" 200 -\n",
            "Created 2 images from text prompt [a beautiful girl putting on make up popart painting]\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 06:58:03] \"POST /dalle HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 06:58:34] \"OPTIONS /dalle HTTP/1.1\" 200 -\n",
            "Created 2 images from text prompt [A dingy dive bar with lots of bikers hanging out dark red interior, wide shot]\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 06:58:58] \"POST /dalle HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 07:04:11] \"OPTIONS / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 07:04:11] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 07:04:18] \"OPTIONS /dalle HTTP/1.1\" 200 -\n",
            "Created 2 images from text prompt [a big tree in the ocean]\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 07:04:42] \"POST /dalle HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 07:04:53] \"OPTIONS /dalle HTTP/1.1\" 200 -\n",
            "Created 2 images from text prompt [a big tree in the ocean photograph rainbow colors]\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 07:05:17] \"POST /dalle HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 07:05:49] \"OPTIONS /dalle HTTP/1.1\" 200 -\n",
            "Created 2 images from text prompt [sipping cocktails by the sunset photograph]\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Jun/2022 07:06:13] \"POST /dalle HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "from threading import Thread\n",
        "\n",
        "def app():\n",
        "  print(f\"Selected DALL-E Model - [{dalle_model}]\")\n",
        "  !python dalle-playground/backend/app.py 8000 $dalle_model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    t1 = Thread(target = app)\n",
        "    a = t1.start()\n",
        "    !lt --port 8000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPhc5fgqT_Q0"
      },
      "source": [
        "### Now, take the url you got from localtunnel (should look like `your url is: https://xxxxxx.loca.lt`), replace it within the url here https://saharmor.github.io/dalle-playground/?backendUrl=https://xxxxxx.loca.lt and run it in the browser. \n",
        "\n",
        "### Let the fun begin ✨"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "DALL-E Playground Backend",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}